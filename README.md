# ğŸµ 4-Stem Music Source Separation

Deep Learning project Ä‘á»ƒ tÃ¡ch nháº¡c thÃ nh 4 stems sá»­ dá»¥ng U-Net architecture: **Vocals, Drums, Bass, Other**

## âœ¨ TÃ­nh nÄƒng chÃ­nh

- ğŸ¤ **4-Stem Separation**: TÃ¡ch vocals, drums, bass, vÃ  other instruments
- ğŸ¤– **U-Net Architecture**: Deep learning model tá»‘i Æ°u cho audio separation
- ğŸš€ **Auto Dataset Download**: Tá»± Ä‘á»™ng táº£i MUSDB18-HQ tá»« Zenodo
- ğŸŒ **Web Interface**: Giao diá»‡n web thÃ¢n thiá»‡n Ä‘á»ƒ tÃ¡ch nháº¡c
- ğŸ“Š **Per-Stem Metrics**: Theo dÃµi loss riÃªng cho tá»«ng stem
- âš¡ **GPU Training**: Há»— trá»£ train trÃªn Colab vá»›i GPU miá»…n phÃ­
- ğŸ›ï¸ **Selective Separation**: Chá»n stems cáº§n tÃ¡ch (khÃ´ng báº¯t buá»™c tÃ¡ch táº¥t cáº£)

## ğŸ¯ Demo

### Input
```
song.mp3 (mixture)
```

### Output
```
song_vocals.wav  â†’ ğŸ¤ Giá»ng hÃ¡t
song_drums.wav   â†’ ğŸ¥ Trá»‘ng
song_bass.wav    â†’ ğŸ¸ Bass
song_other.wav   â†’ ğŸ¹ Nháº¡c cá»¥ khÃ¡c
```

## ğŸ“‹ YÃªu cáº§u há»‡ thá»‘ng

### Minimum
- Python 3.8+
- 8GB RAM (CPU inference)
- 5GB disk space

### Recommended
- Python 3.8+
- 16GB RAM
- NVIDIA GPU vá»›i 8GB+ VRAM (training)
- 50GB disk space (dataset + checkpoints)

## ğŸš€ CÃ i Ä‘áº·t nhanh

### 1. Clone repository
```bash
git clone https://github.com/pvhoaicntt2211/DoAn4MSS.git
cd DoAn4MSS
```

### 2. Táº¡o virtual environment
```bash
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# hoáº·c
.venv\Scripts\activate     # Windows
```

### 3. CÃ i Ä‘áº·t dependencies
```bash
pip install -r requirements.txt
```

## ğŸ“¥ Download Dataset

### Tá»± Ä‘á»™ng (Khuyáº¿n nghá»‹)
```bash
python scripts/download_musdb18.py --output data/
```

Script sáº½:
- âœ… Táº£i MUSDB18-HQ tá»« Zenodo (~30GB)
- âœ… Giáº£i nÃ©n tá»± Ä‘á»™ng
- âœ… Tá»• chá»©c cáº¥u trÃºc thÆ° má»¥c
- âœ… Hiá»ƒn thá»‹ progress bar
- âœ… Skip náº¿u data Ä‘Ã£ tá»“n táº¡i

### Manual
Náº¿u muá»‘n táº£i thá»§ cÃ´ng:
1. Download MUSDB18-HQ: https://zenodo.org/record/3338373
2. Giáº£i nÃ©n vÃ o `data/`
3. Äáº£m báº£o cáº¥u trÃºc:
```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ Song1/
â”‚   â”‚   â”œâ”€â”€ vocals.wav
â”‚   â”‚   â”œâ”€â”€ drums.wav
â”‚   â”‚   â”œâ”€â”€ bass.wav
â”‚   â”‚   â”œâ”€â”€ other.wav
â”‚   â”‚   â””â”€â”€ mixture.wav
â”‚   â””â”€â”€ ...
â””â”€â”€ test/
    â””â”€â”€ ...
```

## ğŸ“ Training

### Local (GPU recommended)
```bash
python train.py \
    --train-dir data/train \
    --valid-dir data/test \
    --epochs 50 \
    --batch-size 8 \
    --lr 1e-4
```

### Google Colab (Khuyáº¿n nghá»‹ cho ngÆ°á»i khÃ´ng cÃ³ GPU)
1. Upload `train_colab.ipynb` lÃªn Colab
2. KÃ­ch hoáº¡t GPU (Runtime â†’ Change runtime type â†’ GPU)
3. Cháº¡y tá»«ng cell theo thá»© tá»±
4. Dataset sáº½ tá»± Ä‘á»™ng download

Chi tiáº¿t: [COLAB_SETUP.md](COLAB_SETUP.md)

### Training Options

```bash
# Äiá»u chá»‰nh batch size náº¿u OOM
python train.py --batch-size 4

# Train nhiá»u workers (Linux)
python train.py --num-workers 4

# Custom learning rate
python train.py --lr 5e-5

# Custom checkpoint directory
python train.py --checkpoint-dir my_checkpoints/
```

### Monitoring Training

Loss Ä‘Æ°á»£c report riÃªng cho tá»«ng stem:
```
Epoch 1/50
Training Loss: 0.0234
  vocals: 0.0198
  drums: 0.0256
  bass: 0.0243
  other: 0.0239
Validation Loss: 0.0187
  vocals: 0.0165
  drums: 0.0201
  bass: 0.0189
  other: 0.0193
âœ… New best model saved
```

## ğŸµ Inference

### Command Line

```bash
# TÃ¡ch táº¥t cáº£ 4 stems
python inference.py song.mp3

# Output vÃ o thÆ° má»¥c khÃ¡c
python inference.py song.mp3 --outdir my_outputs/

# TÃ¡ch chá»‰ vocals vÃ  drums
python inference.py song.mp3 --stems vocals drums

# Sá»­ dá»¥ng checkpoint khÃ¡c
python inference.py song.mp3 --checkpoint my_model.pth
```

### Python API

```python
from inference import separate_file

# TÃ¡ch táº¥t cáº£ stems
output_paths = separate_file(
    input_path="song.mp3",
    output_dir="outputs/",
    checkpoint_path="checkpoints/best_model.pth"
)

# output_paths = {
#     'vocals': 'outputs/song_vocals.wav',
#     'drums': 'outputs/song_drums.wav',
#     'bass': 'outputs/song_bass.wav',
#     'other': 'outputs/song_other.wav'
# }

# TÃ¡ch chá»‰ má»™t sá»‘ stems
output_paths = separate_file(
    input_path="song.mp3",
    stems_to_separate=['vocals', 'drums']
)
```

## ğŸŒ Web Application

### Cháº¡y web app
```bash
python app.py
```

Truy cáº­p: http://localhost:5000

### TÃ­nh nÄƒng Web UI

- ğŸ“¤ Upload audio files (wav, mp3, m4a, flac, ogg)
- â˜‘ï¸ Chá»n stems cáº§n tÃ¡ch (checkboxes)
- ğŸ§ Nghe trá»±c tiáº¿p tá»«ng stem trong browser
- ğŸ’¾ Download riÃªng tá»«ng stem
- ğŸ¨ Giao diá»‡n Ä‘Æ¡n giáº£n, dá»… sá»­ dá»¥ng

### Web App Screenshots

*Upload vÃ  chá»n stems:*
- Chá»n file audio
- Tick cÃ¡c stems muá»‘n tÃ¡ch
- Click "TÃ¡ch ngay"

*Káº¿t quáº£:*
- 4 audio players cho tá»«ng stem
- Buttons download riÃªng
- Option quay láº¡i tÃ¡ch bÃ i khÃ¡c

## âš™ï¸ Configuration

File `config.py` chá»©a cÃ¡c tham sá»‘:

```python
# Model & Training
LEARNING_RATE = 1e-4
BATCH_SIZE = 8
NUM_EPOCHS = 50

# Audio Processing
SAMPLE_RATE = 44100
N_FFT = 2048
HOP_LENGTH = 512
CHUNK_SECONDS = 5

# 4-Stem Configuration
STEMS = ['vocals', 'drums', 'bass', 'other']
STEM_WEIGHTS = {
    'vocals': 1.0,
    'drums': 1.0,
    'bass': 1.0,
    'other': 1.0
}
```

### Äiá»u chá»‰nh Stem Weights

Náº¿u muá»‘n Æ°u tiÃªn má»™t stem hÆ¡n cÃ¡c stem khÃ¡c:

```python
# Æ¯u tiÃªn vocals vÃ  drums
STEM_WEIGHTS = {
    'vocals': 2.0,  # 2x loss weight
    'drums': 1.5,   # 1.5x loss weight
    'bass': 1.0,
    'other': 0.5    # 0.5x loss weight
}
```

## ğŸ“Š Model Architecture

```
U-Net Architecture for 4-Stem Separation

Input: Mixture Spectrogram (1, F, T)
       â†“
[Encoder]
  Conv + BN + ReLU (64)
  â†“ MaxPool
  Conv + BN + ReLU (128)
  â†“ MaxPool
  Conv + BN + ReLU (256)
  â†“ MaxPool
  Conv + BN + ReLU (512)

[Decoder]
  â†‘ UpConv + Skip Connection
  Conv + BN + ReLU (256)
  â†‘ UpConv + Skip Connection
  Conv + BN + ReLU (128)
  â†‘ UpConv + Skip Connection
  Conv + BN + ReLU (64)
       â†“
Output: 4 Masks (4, F, T) â†’ Sigmoid
       â†“
4 Separated Stems: vocals, drums, bass, other
```

## ğŸ“ Project Structure

```
DoAn4MSS/
â”œâ”€â”€ app.py                  # Flask web application
â”œâ”€â”€ config.py               # Configuration constants
â”œâ”€â”€ train.py                # Training script
â”œâ”€â”€ inference.py            # Inference script
â”œâ”€â”€ gui.py                  # Optional GUI (if exists)
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ train_colab.ipynb      # Google Colab notebook
â”œâ”€â”€ COLAB_SETUP.md         # Colab setup guide
â”œâ”€â”€ README.md              # This file
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ download_musdb18.py  # Auto dataset downloader
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ model.py            # U-Net model definition
â”‚   â”œâ”€â”€ dataset.py          # MUSDB dataset loader
â”‚   â””â”€â”€ utils.py            # Utility functions
â”‚
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ index.html          # Upload page
â”‚   â””â”€â”€ result.html         # Results page (4 stems)
â”‚
â”œâ”€â”€ checkpoints/            # Saved model weights
â”œâ”€â”€ data/                   # MUSDB18-HQ dataset
â”‚   â”œâ”€â”€ train/
â”‚   â””â”€â”€ test/
â””â”€â”€ outputs/                # Inference outputs
```

## ğŸ§ª Testing

### Test Dataset Download
```bash
python scripts/download_musdb18.py --output test_data/ --force
```

### Test Inference
```bash
# Táº£i 1 file audio máº«u vÃ  test
python inference.py test_audio.mp3 --outdir test_output/
```

### Test Web App
```bash
python app.py
# Má»Ÿ browser, upload file, verify 4 stems
```

## ğŸ” Troubleshooting

### Out of Memory (OOM)
```bash
# Giáº£m batch size
python train.py --batch-size 4  # hoáº·c 2

# Giáº£m chunk duration trong config.py
CHUNK_SECONDS = 3  # thay vÃ¬ 5
```

### Slow Training
```bash
# TÄƒng workers (Linux/Mac)
python train.py --num-workers 4

# Giáº£m validation frequency
# (sá»­a trong train.py, validate má»—i N epochs thay vÃ¬ má»—i epoch)
```

### Poor Separation Quality
1. Train thÃªm epochs (100+)
2. Äiá»u chá»‰nh stem weights
3. Thá»­ learning rate khÃ¡c nhau
4. ThÃªm data augmentation

### Web App khÃ´ng cháº¡y
```bash
# Check port conflicts
python app.py  # Default: port 5000

# Or specify port
flask run --port 8080
```

## ğŸ“ˆ Performance Benchmarks

### Training Time (50 epochs)

| Hardware | Time/Epoch | Total | Memory |
|----------|------------|-------|---------|
| CPU (16-core) | 60-90 min | ~50-75h | 8GB |
| GPU T4 (Colab) | 10-15 min | 8-12h | 15GB |
| GPU V100 | 5-8 min | 4-7h | 16GB |
| GPU A100 | 3-5 min | 2-4h | 20GB |

### Inference Time (per song ~3-4 min)

| Hardware | Time |
|----------|------|
| CPU | 30-45s |
| GPU T4 | 3-5s |
| GPU V100 | 2-3s |

## ğŸ“ Technical Details

### Loss Function
```python
# Multi-stem L1 Loss
loss = Î£ (STEM_WEIGHTS[stem] Ã— L1(predicted_stem, target_stem))
```

### Mask Application
```python
# Each stem: mask Ã— mixture
vocals = vocals_mask Ã— mixture_spectrogram
drums = drums_mask Ã— mixture_spectrogram
bass = bass_mask Ã— mixture_spectrogram
other = other_mask Ã— mixture_spectrogram
```

### Audio Processing
- Sample Rate: 44.1kHz
- STFT: n_fft=2048, hop_length=512
- Training chunks: 5 seconds
- Phase reconstruction: Original mixture phase

## ğŸ¤ Contributing

Contributions are welcome! Please:
1. Fork repository
2. Create feature branch
3. Commit changes
4. Push to branch
5. Open Pull Request

## ğŸ“ License

This project is for educational purposes.

MUSDB18-HQ dataset: CC BY-NC-SA 4.0 License

## ğŸ™ Acknowledgments

- MUSDB18-HQ dataset by Rafii et al.
- U-Net architecture inspired by Ronneberger et al.
- PyTorch framework
- librosa for audio processing

## ğŸ“§ Contact

For questions or issues:
- GitHub Issues: [Create an issue](https://github.com/pvhoaicntt2211/DoAn4MSS/issues)
- Project maintainer: pvhoaicntt2211

## ğŸ”— References

1. [MUSDB18-HQ Dataset](https://zenodo.org/record/3338373)
2. [U-Net Paper](https://arxiv.org/abs/1505.04597)
3. [Music Source Separation Survey](https://arxiv.org/abs/2010.10671)

---

**Made with â¤ï¸ using PyTorch and librosa**

â­ Star this repo if you find it useful!
